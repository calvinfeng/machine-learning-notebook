{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d309e7bb",
   "metadata": {},
   "source": [
    "# Sampling Bias Corrected Neural Modeling for Large Corpus Item Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b6619",
   "metadata": {},
   "source": [
    "## Modeling Framework: Two-tower\n",
    "\n",
    "We have a set of queries and items. Queries and items are represented by feature vectors\n",
    "\n",
    "- Queries: $\\{x_i\\}^N_{i=1}$\n",
    "- Items: $\\{y_j\\}^M_{j=1}$\n",
    "\n",
    "Here $x_i$ and $y_i$ are both mixtures of a wide variety of features (e.g. sparse IDs and dense features) and could be in a a very high dimensional space. The goal is to retrieve a subset of items given a query. In personalization scenario, we assume user and context are fully captured in $x_i$. Note that we begin with a finite number of queries and items to explain the intuition. Our modeling framework works without such an assumption.\n",
    "\n",
    "We aim to build a model with two parameterized embedding functions:\n",
    "\n",
    "- $u: X \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}^k$\n",
    "- $v: Y \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}^k$\n",
    "\n",
    "They map model parameters $\\theta \\in \\mathbb{R}^d$ and features of query and candidates to a k-dimensional embedding space. The output of the model is the inner product of two embeddings.\n",
    "\n",
    "$$\n",
    "s(x, y) = \\left \\langle u(x, \\theta), v(y, \\theta) \\right \\rangle\n",
    "$$\n",
    "\n",
    "The goal is to learn model parameter $\\theta$ from a training dataset of `T` examples.\n",
    "\n",
    "$$\n",
    "\\tau = \\{(x_i, y_i, r_i)\\}^T_{i=1}\n",
    "$$\n",
    "\n",
    "where $(x_i, y_i)$ denotes the pair of query and item, and $r_i \\in mathbb{R}$ is the associated reward for each pair. The reward does not have to be user ratings. It could be user engagement time or clicks.\n",
    "\n",
    "Given a query $x$, a common choice for the probability distribution of picking candidate $y$ from M items is based on the softmax function.\n",
    "\n",
    "$$\n",
    "P(y \\mid x;\\theta) = \\frac{e^{s(x,y)}}{\\Sigma_{j=1}^{M} e^{s(x,y_j)}}\n",
    "$$\n",
    "\n",
    "By further incorporating rewards $r_i$, we consider the following weighted log-likelihood as the loss function.\n",
    "\n",
    "$$\n",
    "L_{\\tau}(\\theta) = \\frac{-1}{T} \\Sigma_{i \\in T} r_i \\cdot log \\left( P(y_i \\mid x_i; \\theta) \\right)\n",
    "$$\n",
    "\n",
    "When M is very large, it is not feasible to include all candidate examples in computing the denominator. A common idea is to use a subset of items in constructing the denominator. Given a mini-batch of B pairs for each $i \\in B$, the batch softmax is\n",
    "\n",
    "$$\n",
    "P_B(y_i \\mid x_i; \\theta) = \\frac{e^{s(x_i, y_i)}}{\\Sigma_{j \\in B} e^{s(x_i, y_j)}}\n",
    "$$\n",
    "\n",
    "In-batch items are normally sampled from a power-law distribution. As a result, the probability function introduces a large bias toward full softmax: popular items are overly penalized as negatives due to the high probability of being included in a batch. Inspired by the logQ correction used in sampled softmax model, we correct each logit $s(x_i,y_j)$ by the following equation.\n",
    "\n",
    "$$\n",
    "s^c(x_i, y_j) = s(x_i, y_j) - log(p_j)\n",
    "$$\n",
    "\n",
    "Here $p_j$ denotes the sampling probability of item $j$ in a random batch. With the correction, we have\n",
    "\n",
    "$$\n",
    "P_B^c(y_i \\mid x_i; \\theta) = \\frac{e^{s^c(x_i, y_i)}}{e^{s^c(x_i, y_i)} + \\Sigma_{j \\in B, j \\neq i} e^{s^c(x_i, y_j)}}\n",
    "$$\n",
    "\n",
    "The mini-batch loss function is\n",
    "\n",
    "$$\n",
    "L_B(\\theta) = \\frac{-1}{B} \\Sigma_{i \\in B} r_i \\cdot log\\left( P_B^c (y_i \\mid x_i; \\theta) \\right)\n",
    "$$\n",
    "\n",
    "Running SGD with learning rate $\\gamma$ yields the model parameter update as\n",
    "\n",
    "$$\n",
    "\\theta = \\theta - \\gamma \\cdot \\nabla L_B(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5667df57",
   "metadata": {},
   "source": [
    "### Algorithm 1 Training\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "- Two parameterized embedding functions $u(...,\\theta)$ and $v(...,\\theta)$ where each one maps input features to an embedding space through a neural network.\n",
    "\n",
    "- Learning rate $\\gamma$ either fixed or adaptive.\n",
    "\n",
    "**Repeat**\n",
    "\n",
    "- Sample or receive a batch of training data from a stream\n",
    "- Obtain the estimated sampling probability $p_i$ from each $y_i$ from the frequency estimation algorithm below.\n",
    "- Construct loss $L_B(\\theta)$\n",
    "- Apply backpropagation and update $\\theta$\n",
    "\n",
    "**Until** stopping criterion\n",
    "\n",
    "\n",
    "Note that $L_B$ does not require a fixed set of queries or candidates. Accordingly, the gradient update can be applied to streaming training data whose distribution changes over time.\n",
    "\n",
    "### Algorithm 2 Streaming Frequency Estimation\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "- Learning rate $\\alpha$.\n",
    "- Arrays `A` and `B` with size `H`\n",
    "- Hash function `h` with output space `H`\n",
    "\n",
    "**Training**\n",
    "\n",
    "For steps `t = 1, 2, ...`, sample a batch of items $\\beta$. For each $y \\in \\beta$ do:\n",
    "\n",
    "$$\n",
    "B[h(y)] = (1 - \\alpha) \\cdot B[h(y)] + \\alpha \\cdot (t - A[h(y)])\n",
    "$$\n",
    "\n",
    "$$\n",
    "A[h(y)] = t\n",
    "$$\n",
    "\n",
    "**Until** stopping criterion\n",
    "\n",
    "During interference step, for any item $y$, estimated sampling probability\n",
    "\n",
    "$$\n",
    "\\hat{p} = \\frac{1}{B[h(y)]}\n",
    "$$\n",
    "\n",
    "### Normalization and Temperature\n",
    "\n",
    "Empirically we find that adding embedding normalization, i.e.\n",
    "\n",
    "$$\n",
    "u(x, \\theta) = \\frac{u(x, \\theta)}{\\left \\| u(x, \\theta)  \\right \\|_2} \\\\\n",
    "v(y, \\theta) = \\frac{v(y, \\theta)}{\\left \\| v(y, \\theta)  \\right \\|_2}\n",
    "$$\n",
    "\n",
    "improves model trainability and thus leads to better retrieval quality. In addition, a temperature $\\tau$ is added to each logit to sharpen the predictions, namely,\n",
    "\n",
    "$$\n",
    "s(x, y) = \\frac{1}{\\tau} \\left \\langle u(x, \\theta), v(y, \\theta) \\right \\rangle\n",
    "$$\n",
    "\n",
    "In practice $\\tau$ is a hyper-parameter tuned to maximize retrieval metrics such as recall or precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f80ae",
   "metadata": {},
   "source": [
    "## Neural Retrieval System for YouTube\n",
    "\n",
    "YouTube generates video recommendations conditioned on a video (called seed video) being watched by a user. The recommendation system consists of two stages: nomination (a.k.a. retrieval) and ranking. At nomination stage, we have multiple nominators that each generates hundreds of video recommendations given constraints of a user and a seed video. These videos are subsequently scored and re-ranked by a fully-blown neural network ranking model.\n",
    "\n",
    "### Modeling Overview\n",
    "\n",
    "The YouTube neural retrieval model consists of query and candidate networks. At any point of time, the video which a user is watching, i.e. the seed video, provides a strong signal about the user's current interest. As a result, we make use of large set of seed video features along with the user's watch history. The candidate tower is built to learn from candidate video features.\n",
    "\n",
    "**Training Label**\n",
    "\n",
    "Video clicks are used as positive labels. In addition, for each click, we construct a reward $r_i$ to reflect different degrees of user engagement with the video. For example, $r_i = 0$ for clicked videos with little watch time. On the other hand $r_i = 1$ indicates the whole video got watched.\n",
    "\n",
    "**Video Features**\n",
    "\n",
    "The video features include both categorical and dense features. Examples of categorical features include video ID and channel ID. For each of these entities, an embedding layer is created to map each categorical feature to a dense vector.\n",
    "\n",
    "Normally we are dealing with two kinds of categorical features. Some features (e.g. video ID) have strictly one categorical value per video, so we have one embedding vector representing that. Alternatively, one feature (e.g. video topics) might be a sparse vector of categorical values, and the final embedding representing that feature would be a weighted sum of the embeddings for each of the values in the sparse vector.\n",
    "\n",
    "To handle out-of-vocabulary entities, we randomly assign them to a fixed set of hash buckets, and learn an embedding for each one. \n",
    "\n",
    "**User Features**\n",
    "\n",
    "We use a user's watch history to capture the user's interest besides the seed video. One example is a sequence of K video IDs the user recently watched. We treat the watch history as a bag of words, and represent it by the average of video ID embeddings.\n",
    "\n",
    "> Bag of word is treating watch history as a bag of its videos, similar to NLP where a sentence is represented by a list of word IDs. The averaging is presumably finding the centroid in the embedding space.\n",
    "\n",
    "In the query tower, user and seed video features are fused in the input layer, which is then passed through a feed forward neural network.\n",
    "\n",
    "For the same type of IDs, embeddings are shared among the related features. For example, the same set of video ID embddings is used for seed, candidate, and users' past watches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67791f42",
   "metadata": {},
   "source": [
    "![Figure 2](./sampling_bias_corrected_neural_modeling_for_large_corpus_item_recommendations_files/figure_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77876e",
   "metadata": {},
   "source": [
    "### Sequential Training\n",
    "\n",
    "In YouTube, new training data is generated every day, and training datasets are accordingly organized by days. The model training makes use of this sequential structure in the following way.\n",
    "\n",
    "Trainer consumes the data sequentially from the oldest training training examples to most recent training examples. Once the trainer has caught up to the latest day of training data, it waits for the next day's training data to arrive. In this way, the model is able to keep up with latest data distribution shift. Training data is essentially consumed by trainer in a streaming manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507fcd92",
   "metadata": {},
   "source": [
    "### Indexing and Model Serving\n",
    "\n",
    "![Figure 3](./sampling_bias_corrected_neural_modeling_for_large_corpus_item_recommendations_files/figure_3.png)\n",
    "\n",
    "The index pipeline in the retrieval system periodically creates a Tensorflow SavedModel for online serving. The index pipeline was built in three stages.\n",
    "\n",
    "1. Candidate example generation\n",
    "2. Embedding inference\n",
    "3. Embedding indexing\n",
    "\n",
    "In the first stage, a set of videos are selected from YouTube corpus based on certain criterion. Their features are fetched and added to the candidate examples. \n",
    "\n",
    "In the second stage, right tower (candidate tower) is applied to compute embeddings from candidate examples. \n",
    "\n",
    "In the third stage, we train a Tensorflow-based embedding index model based on tree and quantized hashing techniques.\n",
    "\n",
    "Finally, the SavedModel used in serving is created by stitching the query tower and the indexing model together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
