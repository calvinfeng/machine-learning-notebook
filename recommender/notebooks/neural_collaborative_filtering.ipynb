{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering\n",
    "\n",
    "Collaborative filtering is traditionally done with matrix factorization. I did my movie recommendation project using good ol' matrix factorization. However, recently I discovered that people have proposed new ways to do collaborative filtering with deep learning techniques! There's a paper, titled [Neural Collaborative Filtering](https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf), from 2017 which describes the approach to perform collaborative filtering using neural networks.\n",
    "\n",
    "> In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and \n",
    "> natural language processing. However, the exploration of deep neural networks on recommender systems has received \n",
    "> relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the\n",
    "> key problem in recommendation — collaborative filtering — on the basis of implicit feedback.\n",
    "\n",
    "Here's the high level idea.\n",
    "\n",
    "![ncf-high-level](./neural_collaborative_filtering_files/ncf-high-level.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform embedding for each user and item(movie). The embedding layer(s) is simply a matrix dot product of one hot encoding of a user/movie and the embedding weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# We have 10 users, each is uniquely identified by an ID.\n",
    "users = [i for i in range(10)]\n",
    "\n",
    "one_hot_encoding_users = to_categorical(users)\n",
    "print one_hot_encoding_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding vectors will be fed into a deep neural network and its objective is to predict the rating from a user to a movie. For example, user 1 may rate movie 1 with five stars. The network should be able to predict that after training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized Matrix Factorization (GMF)\n",
    "\n",
    "In the context of the paper, a generalized matrix factorization can be described by the following equation.\n",
    "\n",
    "$$\n",
    "\\hat{y}_{ui} = a\\left(h^{T}(p_{u} \\cdot q_{i})\\right)\n",
    "$$\n",
    "\n",
    "where $a$ is an activation function and $h$ is the edge weight matrix of the output layer. The edge weight matrix can be seen as an additional weight to the layer. \n",
    "\n",
    "If we use an identity function for activation and enforce the edge weight matrix to be a uniform vector of 1, we can exactly recover the standard matrix factorization model. However, we will do something more here to make it non-linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten\n",
    "from keras.layers.merge import Dot\n",
    "import keras\n",
    "\n",
    "num_users = 5\n",
    "num_movies = 5\n",
    "latent_dim = 10\n",
    "\n",
    "user_input = Input(shape=(num_users, 1))\n",
    "user_embedding = Embedding(num_users, latent_dim, input_length=1, name='user-embedding')\n",
    "user_flatten = Flatten()\n",
    "\n",
    "user_embedding_model = Model(user_input, user_embedding, user_flatten)\n",
    "\n",
    "movie_input = Input(shape=(num_movies, 1))\n",
    "movie_embedding = Embedding(num_movies, latent_dim, input_length=1, name='movie-embedding')\n",
    "movie_flatten = Flatten()\n",
    "\n",
    "movie_embedding_model = Model(movie_input, movie_embedding, movie_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
