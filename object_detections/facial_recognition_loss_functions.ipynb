{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fd388d",
   "metadata": {},
   "source": [
    "# Facial Recognition Loss Functions\n",
    "\n",
    "This is an overview of loss functions in facial recognition domain. Facial detection problems are slightly different from object detections; there is a need for comparing embeddings between faces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db146e6",
   "metadata": {},
   "source": [
    "## Softmax Loss + Contrastive Loss\n",
    "\n",
    "Notable examples:\n",
    "- [Deep Learning Face Representation by Joint Identification-Verification](https://arxiv.org/abs/1406.4773)\n",
    "- [Deeply learned face representations are sparse, selective, and robust](https://arxiv.org/abs/1412.1265)\n",
    "- [DeepID3: Face Recognition with Very Deep Neural Networks](https://arxiv.org/abs/1502.00873)\n",
    "\n",
    "### Siamese Networks\n",
    "\n",
    "Siamese networt is a class of neural network architectures that contain 2 or more identical sub-networks. They have the same configuration with the same parameters and weights. Basically it's the same network that is used twice before doing backpropagation. They should encode the same information given the same input. However, during training phase, 2 or more inputs are encoded and the output features are compared. It's the same network that's fed 2 or more different pieces of data.\n",
    "\n",
    "Letâ€™s look at an example where we want to make features out of MNIST numbers. Each image of an MNIST number should encode into a vector that is close to vectors from images of the same class. Conversely different numbers should encode into vectors that are far from each other.\n",
    "\n",
    "![Similar Numbers](./assets/embed-to-vector-space.png)\n",
    "\n",
    "Since we have the class labels for MNIST digits, we could use a regular CNN and categorical cross-entropy loss to finish the job. However, for facial data, we don't have the labels for every individual in the data set. This is where contrastive loss comes in.\n",
    "\n",
    "> Contrastive loss takes the output of the network for a positive example and calcluate its distance to an example of the same class and contrasts that with the distance to negative examples.\n",
    "\n",
    "Minimizing loss is equivalent to encoding similar samples closer to together and different samples farther apart. This is accomplished by taking the **cosine distances** of the vectors and treating the resulting distances as prediction probabilities from a typical classification network. \n",
    "\n",
    "## Loss\n",
    "\n",
    "Here's an example called [Normalized Temperature-scaled Cross Entropy Loss](https://paperswithcode.com/method/nt-xent)\n",
    "\n",
    "Let's define temperature-scaled distance as\n",
    "\n",
    "$$\n",
    "d(z_i, z_j) = \\frac{\\text{sim}(z_i, z_j)}{\\tau}\n",
    "$$\n",
    "\n",
    "where $\\text{sim}(u,v)$ is the cosine similarity between two vectors, and $\\tau$ is called a temperature parameter.\n",
    "\n",
    "$$\n",
    "L(i, j) = -\\text{log} \\frac{ \\text{exp}(d(z_i, z_j))}{ \\Sigma_{k=1}^{2N} \\text{exp}(d(z_i, z_k))} \n",
    "$$\n",
    "\n",
    "Now why is there 2N? This will be explained in [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/pdf/2002.05709v3.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fba7cad",
   "metadata": {},
   "source": [
    "## Triplet Loss\n",
    "\n",
    "Notable examples:\n",
    "- [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/abs/1503.03832)\n",
    "- [Targeting Ultimate Accuracy: Face Recognition via Deep Embedding](https://arxiv.org/abs/1506.07310)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d348993",
   "metadata": {},
   "source": [
    "## Center Loss\n",
    "\n",
    "Notable examples:\n",
    "- [A Discriminative Feature Learning Approach\n",
    "for Deep Face Recognition](http://ydwen.github.io/papers/WenECCV16.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20945290",
   "metadata": {},
   "source": [
    "## Large Margin Softmax Loss\n",
    "\n",
    "Notable examples:\n",
    "- [Large-Margin Softmax Loss for Convolutional Neural Networks](https://arxiv.org/abs/1612.02295)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01014ebe",
   "metadata": {},
   "source": [
    "## Angular Softmax Loss\n",
    "\n",
    "Notable examples:\n",
    "- [SphereFace: Deep Hypersphere Embedding for Face Recognition](https://arxiv.org/abs/1704.08063)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a19d2f8",
   "metadata": {},
   "source": [
    "## Feature Normalization Loss\n",
    "\n",
    "Notable examples:\n",
    "- [NormFace: L2 Hypersphere Embedding for Face Verification](https://arxiv.org/abs/1704.06369)\n",
    "- [Learning Deep Features via Congenerous Cosine Loss for Person Recognition](https://arxiv.org/abs/1702.06890)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6dd83",
   "metadata": {},
   "source": [
    "## Cosine Loss\n",
    "\n",
    "- [CosFace: Large Margin Cosine Loss for Deep Face Recognition](https://arxiv.org/abs/1801.09414)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
