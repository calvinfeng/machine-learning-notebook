{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a28877-ebd4-4013-bcac-29fef493b5b7",
   "metadata": {},
   "source": [
    "# Backpropagation Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851eb19b",
   "metadata": {},
   "source": [
    "The objective of this notebook is to compute gradients without the help of TensorFlow or PyTorch autograd. I will derive the gradients of \n",
    "\n",
    "- Affine transformation, a.k.a. Dense layer in TensorFlow Keras\n",
    "- ReLU Activation\n",
    "- Sigmoid Activation\n",
    "- Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b5497-b868-43c6-8069-3ca673ca8cd8",
   "metadata": {},
   "source": [
    "## Demonstrate with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3ebeb4-c9ff-4233-812a-ea6894e8e009",
   "metadata": {},
   "source": [
    "Let's start with how TensorFlow computes gradient with backpropagation. Here is a simple architecture with `input_shape=(3,3)` and `batch_size=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72447acf-a246-4e1e-9cc2-dbfa153b3e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 20:44:22.740357: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-27 20:44:22.865325: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-27 20:44:23.444058: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-27 20:44:23.444146: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-27 20:44:23.444154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import RandomNormal, Zeros\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f087e4b-3de2-434b-887e-b60f1f9ad713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 6)                 12        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 20:44:24.270934: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-27 20:44:24.276865: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-27 20:44:24.276892: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-27 20:44:24.277357: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "tf_model = Sequential([\n",
    "    Dense(6, activation=\"relu\", name=\"dense_1\", kernel_initializer=RandomNormal(stddev=0.01), bias_initializer=Zeros()),\n",
    "    Dense(3, activation=\"relu\", name=\"dense_2\", kernel_initializer=RandomNormal(stddev=0.01), bias_initializer=Zeros()),\n",
    "    Dense(1, activation=\"sigmoid\", name=\"dense_3\", kernel_initializer=RandomNormal(stddev=0.01), bias_initializer=Zeros()),\n",
    "])\n",
    "tf_model.build((None, 1))\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588d0852-f3f9-41d2-89e5-29f22687cbfc",
   "metadata": {},
   "source": [
    "To keep things simple, I want my model to learn `sine` function. I define a L2 loss function. Since my model uses activation layers, the outputs should match that of `sine`.\n",
    "\n",
    "$$\n",
    "\\text{sin}(x) = \\text{model}(x) = \\hat{y} \\in [0, 1]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3776e035-5f86-4840-9f7f-a222d43eb6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.  1.1 1.2 1.3 1.4 1.5 1.6 1.7\n",
      " 1.8 1.9 2.  2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.  3.1]\n",
      "Output: \n",
      " [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5\n",
      " 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "Loss:\n",
      " 0.116013035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6b5013ed00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0., 3.2, 0.1)\n",
    "y_true = np.sin(x)\n",
    "\n",
    "x = np.expand_dims(x, axis=-1)\n",
    "y_true = np.expand_dims(y_true, axis=-1)\n",
    "\n",
    "y_pred = tf_model(x).numpy()\n",
    "mse = MeanSquaredError()\n",
    "loss = mse(y_true, y_pred).numpy()\n",
    "\n",
    "print(\"Input:\\n\", x.flatten())\n",
    "print(\"Output: \\n\", np.round(y_pred, decimals=2).flatten())\n",
    "print(\"Loss:\\n\", loss)\n",
    "plt.plot(x.flatten(), y_true.flatten(), label=\"Ground Truth\")\n",
    "plt.plot(x.flatten(), y_pred.flatten(), label=\"Prediction\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16031c99-16fe-40e0-840b-68583698d216",
   "metadata": {},
   "source": [
    "Compute gradients using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93aa33f0-3338-4645-921e-00d16ec4fadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: dense_1/kernel:0\n",
      "Gradient:\n",
      " [[-2.4163039e-06  3.4067969e-07  2.6594885e-06  0.0000000e+00\n",
      "   3.4254313e-06  4.0333862e-06]] \n",
      "\n",
      "Variable: dense_1/bias:0\n",
      "Gradient:\n",
      " [-1.6388769e-06  2.3106867e-07  1.8038187e-06  0.0000000e+00\n",
      "  2.3233249e-06  2.7356755e-06] \n",
      "\n",
      "Variable: dense_2/kernel:0\n",
      "Gradient:\n",
      " [[4.9851053e-07 0.0000000e+00 1.8573847e-07]\n",
      " [2.2979732e-06 0.0000000e+00 8.5619433e-07]\n",
      " [3.2535436e-06 0.0000000e+00 1.2122276e-06]\n",
      " [0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      " [6.0896434e-07 0.0000000e+00 2.2689213e-07]\n",
      " [1.8945034e-06 0.0000000e+00 7.0586702e-07]] \n",
      "\n",
      "Variable: dense_2/bias:0\n",
      "Gradient:\n",
      " [2.2116188e-04 0.0000000e+00 8.2402003e-05] \n",
      "\n",
      "Variable: dense_3/kernel:0\n",
      "Gradient:\n",
      " [[-1.4289822e-05]\n",
      " [ 0.0000000e+00]\n",
      " [-8.5941047e-06]] \n",
      "\n",
      "Variable: dense_3/bias:0\n",
      "Gradient:\n",
      " [-0.06242947] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y_pred = tf_model(x)\n",
    "    loss = mse(y_true, y_pred)\n",
    "    \n",
    "gradients = tape.gradient(loss, tf_model.trainable_variables)\n",
    "for var, grad in zip(tf_model.trainable_variables, gradients):\n",
    "    print(\"Variable:\", var.name)\n",
    "    print(\"Gradient:\\n\", grad.numpy(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffad239-5f80-42f0-ac8d-1d5f2e15b4c0",
   "metadata": {},
   "source": [
    "## Demonstrate with Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c2f5f5-5266-427a-9370-f4d39d5f66e9",
   "metadata": {},
   "source": [
    "Without the help of auto differentiation, now I need to write the same functionality with numpy and some calculus. For weight initialization, keep in mind that\n",
    "`numpy` returns random normal distribution with `mean=0` and `std=1`. A new random normal distribution can be defined as follows.\n",
    "\n",
    "$$\n",
    "X^\\prime = \\sigma X + \\mu\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc653b5a-5735-4ea3-85f8-4ae0ff9a457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyModel:\n",
    "    \"\"\"Model V1 will only perform forward propagation.\n",
    "    \"\"\"\n",
    "    def __init__(self, weight_stddev=0.01):\n",
    "        self.params = {\n",
    "            \"dense_1/kernel\": weight_stddev * np.random.randn(1, 6),\n",
    "            \"dense_1/bias\": np.zeros((6,)),\n",
    "            \"dense_2/kernel\": weight_stddev * np.random.randn(6, 3),\n",
    "            \"dense_2/bias\": np.zeros((3,)),\n",
    "            \"dense_3/kernel\": weight_stddev * np.random.randn(3, 1),\n",
    "            \"dense_3/bias\": np.zeros((1,)),\n",
    "        }\n",
    "        \n",
    "        self.activations = {\n",
    "            \"dense_1/act\": self._relu,\n",
    "            \"dense_2/act\": self._relu,\n",
    "            \"dense_3/act\": self._sigmoid\n",
    "        }\n",
    "\n",
    "        self.forward_cache = {}\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.forward_cache = {\n",
    "            \"input\": x\n",
    "        } \n",
    "        \n",
    "        x = np.matmul(x, self.params['dense_1/kernel']) + self.params['dense_1/bias']\n",
    "        self.forward_cache[\"affine_1\"] = x\n",
    "        x = self.activations['dense_1/act'](x)\n",
    "        self.forward_cache[\"affine_1_act\"] = x\n",
    "        \n",
    "        x = np.matmul(x, self.params['dense_2/kernel']) + self.params['dense_2/bias']\n",
    "        self.forward_cache[\"affine_2\"] = x\n",
    "        x = self.activations['dense_2/act'](x)\n",
    "        self.forward_cache[\"affine_2_act\"] = x\n",
    "        \n",
    "        x = np.matmul(x, self.params['dense_3/kernel']) + self.params['dense_3/bias']\n",
    "        self.forward_cache[\"affine_3\"] = x\n",
    "        x = self.activations['dense_3/act'](x)\n",
    "        self.forward_cache[\"affine_3_act\"] = x\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _relu(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-1 * x))\n",
    "    \n",
    "    def mean_squared_error(self, y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3669115f-ab39-46f6-8050-5f53a10a87fb",
   "metadata": {},
   "source": [
    "Now I have a model that produces the output and loss value like the TensorFlow model I setup above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cf5ce9-604c-46ac-aca2-002e8da44507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.  1.1 1.2 1.3 1.4 1.5 1.6 1.7\n",
      " 1.8 1.9 2.  2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.  3.1]\n",
      "Output: \n",
      " [0.5        0.5000001  0.50000021 0.50000031 0.50000041 0.50000051\n",
      " 0.50000062 0.50000072 0.50000082 0.50000092 0.50000103 0.50000113\n",
      " 0.50000123 0.50000133 0.50000144 0.50000154 0.50000164 0.50000174\n",
      " 0.50000185 0.50000195 0.50000205 0.50000215 0.50000226 0.50000236\n",
      " 0.50000246 0.50000256 0.50000267 0.50000277 0.50000287 0.50000297\n",
      " 0.50000308 0.50000318]\n",
      "Loss:\n",
      " [0.11601256]\n"
     ]
    }
   ],
   "source": [
    "np_model = NumpyModel()\n",
    "\n",
    "y_pred = np_model(x)\n",
    "loss = np_model.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print(\"Input:\\n\", x.flatten())\n",
    "print(\"Output: \\n\", y_pred.flatten())\n",
    "print(\"Loss:\\n\", loss.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b58ef1-bd29-4cd9-b3d3-39404a838a37",
   "metadata": {},
   "source": [
    "## Computing Gradient Analytically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd7892-e765-4dfb-8a8f-fb312fc3f600",
   "metadata": {},
   "source": [
    "### Gradient of Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125bae5-e2d3-4f78-ba76-79de91a9362d",
   "metadata": {},
   "source": [
    "The L2 loss is defined as follows.\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{N}\\Sigma_{i=0}^{N-1} (y_{i} - \\hat{y}_{i})^2\n",
    "$$\n",
    "\n",
    "The derivative of loss with respect to prediction is then:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{y}} = \\frac{2}{N} \\cdot (y - \\hat{y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71a078e2-f4a2-4690-b824-4b94e6d530fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03125   ,  0.02501042,  0.01883318,  0.01278001,  0.00691138,\n",
       "        0.00128594, -0.00404012, -0.00901356, -0.0135847 , -0.01770787,\n",
       "       -0.02134187, -0.02445039, -0.02700237, -0.0289723 , -0.03034052,\n",
       "       -0.03109334, -0.03122325, -0.03072894, -0.02961536, -0.02789363,\n",
       "       -0.02558096, -0.02270045, -0.01928088, -0.01535643, -0.01096629,\n",
       "       -0.00615435, -0.00096867,  0.00453893,  0.01031342,  0.0162971 ,\n",
       "        0.02243019,  0.02865141])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_y_pred = 2 * (y_pred - y_true) / np.prod(y_pred.shape)\n",
    "grad_y_pred.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f30cfa-ab87-4e9f-a99f-45938b22f665",
   "metadata": {},
   "source": [
    "### Gradient of Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ce109c-2ec3-4049-a231-ecf154bc82d2",
   "metadata": {},
   "source": [
    "The activation of last layer is a sigmoid function.\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "The input `x` is the output from `dense_3` layer. Let's call it $A_3$, given that it's the output of an affine transformation. Then the derivative of sigmoid function or `y_pred` with respect to $A_3$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\sigma}{\\partial A_3} = (1 - \\sigma(A_3)) * \\sigma(A_3) =  \\frac{\\partial \\hat{y}}{\\partial A_3} = (1 - \\hat{y}) * \\hat{y}\n",
    "$$\n",
    "\n",
    "I want the gradient of loss with respect to $A_3$. I need to apply **chain rule** here.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_3} = \\frac{\\partial L}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial A_3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1890a6cc-3b01-4227-aa71-7bd5ccd02b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affine 3 gradient shape (32, 1)\n"
     ]
    }
   ],
   "source": [
    "grad_affine_3 = grad_y_pred * (1 - y_pred) * y_pred\n",
    "print(\"Affine 3 gradient shape\", grad_affine_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d7ad4-dd64-4eee-883e-584ea4fbb479",
   "metadata": {},
   "source": [
    "### Gradient of Trainable Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304e096-ddac-4b4e-89cb-b9585604a79e",
   "metadata": {},
   "source": [
    "So far none of the gradients I have computed should be applied to any variable because the loss and activation functions above do not contain any parameters. However, I can use chain rules to **backpropagate** gradients to my trainable variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5048e76-e717-4fac-b98d-3d2f843bb63c",
   "metadata": {},
   "source": [
    "The first trainable variables, counting from the output, are `dense_3_kernel` and `dense_3_bias`. These two variables along with input from previous layer produces the affine output.\n",
    "\n",
    "$$\n",
    "A_3 = xW_3 + b_3 = \\text{ReLU}(A_2)W_3 + b_3\n",
    "$$\n",
    "\n",
    "The gradient of affine with respect to kernel and bias are:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial A_3}{\\partial W_3} = x\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial A_3}{\\partial b_3} = 1\n",
    "$$\n",
    "\n",
    "But I am more interested in the gradient of loss with respect to kernel and bias. So I apply chain rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_3} = \\frac{\\partial L}{\\partial \\hat{y}}\\frac{\\partial \\hat{y}}{\\partial A_3}\\frac{\\partial A_3}{\\partial W_3} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_3} = \\frac{\\partial L}{\\partial \\hat{y}}\\frac{\\partial \\hat{y}}{\\partial A_3}\\frac{\\partial A_3}{\\partial b_3} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4e8149-7280-4a5b-a8f5-7c94c3e4135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense 3 kernel shape (3, 1)\n",
      "Dense 3 kernel gradient shape (3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense 3 kernel shape\", np_model.params['dense_3/kernel'].shape)\n",
    "grad_dense_3_kernel = np.matmul(np_model.forward_cache[\"affine_2_act\"].T, grad_affine_3)\n",
    "print(\"Dense 3 kernel gradient shape\", grad_dense_3_kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfbf68b0-ef3e-474f-a81c-5b6839c80452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense 3 bias shape (1,)\n",
      "Dense 3 bias gradient shape (1,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense 3 bias shape\", np_model.params['dense_3/bias'].shape)\n",
    "grad_dense_3_bias = np.sum(grad_affine_3.T * 1, axis=1)\n",
    "print(\"Dense 3 bias gradient shape\", grad_dense_3_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f34221-a3c9-49ca-a195-d7b7288f28c8",
   "metadata": {},
   "source": [
    "### Gradients of ReLU Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa6d11-902b-4e1d-94ec-c003ca521d27",
   "metadata": {},
   "source": [
    "Repeat the same process for `dense_2` layer. However, I have `ReLU` activation and its gradient is slightly different from sigmoid activation.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{ReLU}}{\\partial x} = \\frac{\\partial \\text{ReLU}}{\\partial A_2} = \\begin{cases}\n",
    "1 & \\text{ if } x \\gt 0 \\\\ \n",
    "0 & \\text{ else }  \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "What I need is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial \\hat{y}}\\frac{\\partial \\hat{y}}{\\partial A_3}\\frac{\\partial A_3}{\\partial \\;\\text{ReLU}} \\frac{\\partial \\text{ReLU}}{\\partial A_2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c407f73c-4de2-42e1-b94f-492bbba94753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affine 2 shape (32, 3)\n",
      "Affine 2 gradient shape (32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Affine 2 shape\", np_model.forward_cache[\"affine_2\"].shape)\n",
    "\n",
    "grad_affine_2_act = np.matmul(grad_affine_3, np_model.params['dense_3/kernel'].T)\n",
    "grad_affine_2 = grad_affine_2_act.copy()\n",
    "grad_affine_2[np_model.forward_cache[\"affine_2\"] < 0] = 0 # ReLU Backprop\n",
    "print(\"Affine 2 gradient shape\", grad_affine_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5cb784-f76d-41cf-bebe-bfbf9888f230",
   "metadata": {},
   "source": [
    "Then I can compute the gradients of layer 2 kernel weights and bias.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_2} = \\frac{\\partial L}{\\partial A_2} \\frac{\\partial A_2}{\\partial W_2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d98f0d3-f9bf-4b4d-a7a7-09e19928e3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense 2 kernel shape (6, 3)\n",
      "Dense 2 kernel gradient shape (6, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense 2 kernel shape\", np_model.params['dense_2/kernel'].shape)\n",
    "grad_dense_2_kernel = np.matmul(np_model.forward_cache[\"affine_1_act\"].T, grad_affine_2)\n",
    "print(\"Dense 2 kernel gradient shape\", grad_dense_2_kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cd80711-5d62-4a53-9022-4f38620e0707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense 2 bias shape (3,)\n",
      "Dense 2 bias gradient shape (3,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense 2 bias shape\", np_model.params['dense_2/bias'].shape)\n",
    "grad_dense_2_bias = np.sum(grad_affine_2.T * 1, axis=1)\n",
    "print(\"Dense 2 bias gradient shape\", grad_dense_2_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a23cfab-8d1c-4fdd-bd2d-97c70d649eb5",
   "metadata": {},
   "source": [
    "Finally, repeat the same process for `dense_1` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9af5c37d-a71b-4ad2-a9d8-23f40dc6d048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affine 1 shape (32, 6)\n",
      "Affine 1 gradient shape (32, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Affine 1 shape\", np_model.forward_cache[\"affine_1\"].shape)\n",
    "grad_affine_1_act = np.matmul(grad_affine_2, np_model.params['dense_2/kernel'].T)\n",
    "\n",
    "grad_affine_1 = grad_affine_1_act.copy()\n",
    "grad_affine_1[np_model.forward_cache[\"affine_1\"] < 0] = 0\n",
    "print(\"Affine 1 gradient shape\", grad_affine_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e7b912b-5df3-4d98-8658-a8f24af2268b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense 1 kernel shape (1, 6)\n",
      "Dense 1 kernel gradient shape (1, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense 1 kernel shape\", np_model.params['dense_1/kernel'].shape)\n",
    "grad_dense_1_kernel = np.matmul(np_model.forward_cache[\"input\"].T, grad_affine_1)\n",
    "print(\"Dense 1 kernel gradient shape\", grad_dense_1_kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eb1a96b-2251-42f0-938c-fca894b1b4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense 1 bias shape (6,)\n",
      "Dense 1 bias gradient shape (6,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense 1 bias shape\", np_model.params['dense_1/bias'].shape)\n",
    "grad_dense_1_bias = np.sum(grad_affine_1 * 1, axis=0)\n",
    "print(\"Dense 1 bias gradient shape\", grad_dense_1_bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ed866-c48c-4676-9468-683fb7a29d3e",
   "metadata": {},
   "source": [
    "Look at the values of all the gradients computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4a190ed-eebb-46a9-93e5-ae2086283817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense 3 kernel gradients\n",
      " [[-1.98181719e-05]\n",
      " [ 0.00000000e+00]\n",
      " [ 0.00000000e+00]]\n",
      "Dense 3 bias gradients\n",
      " [-0.06242857]\n",
      "Dense 2 kernel gradients\n",
      " [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.52788221e-05  0.00000000e+00  0.00000000e+00]\n",
      " [-1.07824496e-05  0.00000000e+00  0.00000000e+00]\n",
      " [-1.90400976e-05  0.00000000e+00  0.00000000e+00]]\n",
      "Dense 2 bias gradients\n",
      " [-1.33831172e-03  4.31246958e-05 -1.39318192e-04]\n",
      "Dense 1 kernel gradients\n",
      " [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.14487300e-05\n",
      "  -3.66081806e-06 -2.22284226e-05]]\n",
      "Dense 1 bias gradients\n",
      " [ 2.42460285e-06  8.34986187e-07  1.92251618e-06 -1.84455999e-05\n",
      "  4.32125198e-08 -1.08221797e-05]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dense 3 kernel gradients\\n\", grad_dense_3_kernel)\n",
    "print(\"Dense 3 bias gradients\\n\", grad_dense_3_bias)\n",
    "print(\"Dense 2 kernel gradients\\n\", grad_dense_2_kernel)\n",
    "print(\"Dense 2 bias gradients\\n\", grad_dense_2_bias)\n",
    "print(\"Dense 1 kernel gradients\\n\", grad_dense_1_kernel)\n",
    "print(\"Dense 1 bias gradients\\n\", grad_dense_1_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f4493-9241-4c0e-8692-0a07533cef72",
   "metadata": {},
   "source": [
    "## Computing Gradient Numerically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c6795c-6ef3-464e-8249-4dfc5dc76d2c",
   "metadata": {},
   "source": [
    "I can define gradients using limits.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{y}} = \\lim_{\\delta \\to 0}  \\frac{L(\\hat{y} + \\delta) + L(\\hat{y} - \\delta)}{2\\delta}\n",
    "$$\n",
    "\n",
    "The same concept applies to every trainable variable, for example:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{3, i, j}} = \\lim_{\\delta \\to 0}  \\frac{L(W_{3,i,j} + \\delta) + L(W_{3, i, j} - \\delta)}{2\\delta}\n",
    "$$\n",
    "\n",
    "Be aware that the loss and $\\delta$ are scalars, each time I add perturbation to kernel weight, I must add $\\delta$ to a single parameter on a given kernel. This is a very computionally inefficient method but it helps to provide a sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34f6898-819b-49d6-88d7-1e85b5b467aa",
   "metadata": {},
   "source": [
    "Use `numpy.nditer` to provide multi-index iteration. This will save me the trouble of iterating through `i` and `j` and speed things up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61c80ede-bf55-42da-80f8-3736262192c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(model, param_name, y_true, delta=1e-8):\n",
    "    numerical_grad = np.zeros_like(model.params[param_name])\n",
    "    nditer = np.nditer(numerical_grad, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    while not nditer.finished:\n",
    "        idx = nditer.multi_index\n",
    "\n",
    "        param = model.params[param_name][idx]\n",
    "    \n",
    "        model.params[param_name][idx] = param + delta\n",
    "        y_pred = model(x)\n",
    "        loss_pos_delta = model.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "        model.params[param_name][idx] = param - delta\n",
    "        y_pred = model(x)\n",
    "        loss_neg_delta = model.mean_squared_error(y_true, y_pred)\n",
    "        \n",
    "        numerical_grad[idx] = (loss_pos_delta - loss_neg_delta) / (2 * delta)\n",
    "        \n",
    "        model.params[param_name][idx] = param\n",
    "        nditer.iternext()\n",
    "    \n",
    "    return numerical_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b1b3ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0., 3.2, 0.1)\n",
    "y_true = np.sin(x)\n",
    "\n",
    "x = np.expand_dims(x, axis=-1)\n",
    "y_true = np.expand_dims(y_true, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba2629a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.9817481e-05],\n",
       "       [ 0.0000000e+00],\n",
       "       [ 0.0000000e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_grad_dense_3_kernel = numerical_gradient(np_model, 'dense_3/kernel', y_true)\n",
    "numerical_grad_dense_3_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8815c7f",
   "metadata": {},
   "source": [
    "The numerical gradient values should be closely approximate the analytical gradient values. However, they should not be exact match because numerical gradient, afterall, is an approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "658a85f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(numerical_grad_dense_3_kernel, grad_dense_3_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ef513ea-2c9b-4117-a7a5-6aafaf847805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(numerical_gradient(np_model, 'dense_3/bias', y_true), grad_dense_3_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6e2d02b-87c3-4fe6-8652-e57629041ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(numerical_gradient(np_model, 'dense_2/kernel', y_true), grad_dense_2_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d379bc21-1d02-4e06-93ac-64f2ca47191e",
   "metadata": {},
   "source": [
    "Gradients of bias seem to be less precise as the gradient is back-propagated into deeper layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a61c0dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical: [-0.0014  0.     -0.0001]\n",
      "Analytical: [-0.0013  0.     -0.0001]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_grad_dense_2_bias = numerical_gradient(np_model, 'dense_2/bias', y_true)\n",
    "print(\"Numerical:\", np.round(num_grad_dense_2_bias, decimals=4))\n",
    "print(\"Analytical:\", np.round(grad_dense_2_bias, decimals=4))\n",
    "np.allclose(num_grad_dense_2_bias, grad_dense_2_bias, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80049a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(numerical_gradient(np_model, 'dense_1/kernel', y_true), grad_dense_1_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dd46626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical: [ 0.  0.  0. -0. -0. -0.]\n",
      "Analytical: [ 0.  0.  0. -0.  0. -0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_grad_dense_1_bias = numerical_gradient(np_model, 'dense_1/bias', y_true)\n",
    "print(\"Numerical:\", np.round(num_grad_dense_1_bias, decimals=4))\n",
    "print(\"Analytical:\", np.round(grad_dense_1_bias, decimals=4))\n",
    "np.allclose(num_grad_dense_1_bias, grad_dense_1_bias, atol=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
