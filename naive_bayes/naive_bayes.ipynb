{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Naive Bayes Model \n",
    "\n",
    "## Introduction\n",
    "Using the Enron email data set, we will create a Naive Bayesian network in this simple exercise to classify whether a given email is a spam or ham by looking at its word frequency as feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Mathematics\n",
    "### Definitions\n",
    "\n",
    "Let's define $N$ to be the number of total emails we have in the dataset and $N_{s}$ to be the number of spam emails in the email set.\n",
    "\n",
    "$N_{so}$ is the number of spam emails that contain the word \"offer\"\n",
    "\n",
    "$N_{o}$ is the number of emails that contain the word \"offer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then the probability of having a spam email in the set is said to be:\n",
    "\n",
    "$$\n",
    "P(SPAM=1) = \\frac{N_{s}}{N}\n",
    "$$ \n",
    "\n",
    "And the probability of having an email that contains the word *offer* is:\n",
    "\n",
    "$$\n",
    "P(OFFER=1) = \\frac{N_{o}}{N}\n",
    "$$\n",
    "\n",
    "Finally, the conditional probability of an email being a spam email given that it contains the word *offer*:\n",
    "\n",
    "$$\n",
    "P(SPAM=1\\mid OFFER=1) := \\frac{N_{so}}{N_{o}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Postulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If the probability of finding the word *offer* given that it's a spam email is higher than that of finding the word *offer* in a non-spam email:\n",
    "\n",
    "$$\n",
    "P(OFFER =1 \\mid SPAM=1)  > P(OFFER = 1 \\mid SPAM=0)\n",
    "$$\n",
    "\n",
    "then we can infer that:\n",
    "\n",
    "$$\n",
    "P(SPAM=1 \\mid OFFER=1) > P(SPAM = 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "P(SPAM=1 \\mid OFFER=1) = \\frac{P(OFFER=1 \\mid SPAM=1)P(SPAM=1)}{P(OFFER=1)} = \\frac{\\frac{N_{so}}{N_{s}}\\frac{N_{s}}{N}}{\\frac{N_{o}}{N}} = \\frac{N_{so}}{N_{o}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is known as the **Bayes' rule**, famously stated as $P(A \\mid B)=\\frac{P(B \\mid A)P(A)}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\n",
    "P(SPAM=0 \\mid OFFER=1) = \\frac{P(OFFER=1 \\mid SPAM=0)P(SPAM=0)}{P(OFFER=1)} \\\\\n",
    "P(SPAM=1 \\mid OFFER=1) = \\frac{P(OFFER=1 \\mid SPAM=1)P(SPAM=1)}{P(OFFER=1)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For abbreviation, let's define that:\n",
    "\n",
    "$$\n",
    "P(SPAM=1) := P(S) \\\\\n",
    "P(OFFER=1 \\mid SPAM=1) := P(O \\mid S) \\\\\n",
    "P(OFFER=1 \\mid SPAM=0) := P(O \\mid S_{c}) \\\\\n",
    "P(SPAM=1 \\mid OFFER=1):= P(S \\mid O)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Begin with\n",
    "\n",
    "$$\n",
    "P(O \\mid S) > P(O \\mid S_{c})\n",
    "$$\n",
    "\n",
    "Rewrite them using **Bayes' rule**:\n",
    "\n",
    "$$\n",
    "\\frac{P(S \\mid O) P(O)}{P(S)} > \\frac{P(S_{c} \\mid O)P(O)}{P(S_{c})}\n",
    "$$\n",
    "\n",
    "The $P(O)$ terms cancel out each other:\n",
    "\n",
    "$$\n",
    "\\frac{P(S \\mid O)}{P(S)} > \\frac{P(S_{c} \\mid O)}{P(S_{c})}\n",
    "$$\n",
    "\n",
    "By definition, we can rewrite the right hand side as the following:\n",
    "\n",
    "$$\n",
    "\\frac{P(S \\mid O)}{P(S)} > \\frac{1 - P(S \\mid O)}{1 - P(S)}\n",
    "$$\n",
    "\n",
    "Re-organize the terms:\n",
    "\n",
    "$$\n",
    "\\frac{1 - P(S)}{P(S)} > \\frac{1 - P(S \\mid O)}{P(S \\mid O)}\n",
    "$$\n",
    "\n",
    "Then we can easily see that:\n",
    "\n",
    "$$\n",
    "\\frac{1}{P(S)} - 1 > \\frac{1}{P(S \\mid O)} - 1 \\\\\n",
    "\\frac{1}{P(S)} > \\frac{1}{P(S \\mid O)} \\\\\n",
    "$$\n",
    "\n",
    "**Q.E.D.**\n",
    "$$\n",
    "P(S \\mid O) > P(S)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature Probability\n",
    "First of all, we load the data into a class object called `EmailSet` and compute the feature probability for each word that has appeared in the email using `FeatureProbability.from_email_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already processed!\n",
      "Feature probability set has 3672 ham emails.\n",
      "Feature probability set has 1500 spam emails.\n"
     ]
    }
   ],
   "source": [
    "from naive_bayes.email_set import EmailSet\n",
    "from naive_bayes.email_set import build_and_save_email_set\n",
    "from naive_bayes.feature_prob_set import FeatureProbabilitySet\n",
    "\n",
    "# If you haven't pickled it, then run \n",
    "build_and_save_email_set()\n",
    "\n",
    "es = EmailSet.get()\n",
    "fps = FeatureProbabilitySet.from_email_set(es)\n",
    "\n",
    "print \"Feature probability set has %s ham emails.\" % fps.class_count.ham_count\n",
    "print \"Feature probability set has %s spam emails.\" % fps.class_count.spam_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code:3751 with count: {'spam_count': 141, 'ham_count': 61}\n",
      "Prob ratio: 5.65849180328\n"
     ]
    }
   ],
   "source": [
    "code = es.word_encoding_dictionary.word_to_code(\"offer\")\n",
    "print \"Code:%s with count: %s\" % (code, fps.code_count[code])\n",
    "print \"Prob ratio: %s\" % fps.code_prob_ratio(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code:14526 with count: {'spam_count': 0, 'ham_count': 1}\n",
      "Prob ratio: 0.0\n"
     ]
    }
   ],
   "source": [
    "code = es.word_encoding_dictionary.word_to_code(\"compensating\")\n",
    "print \"Code:%s with count: %s\" % (code, fps.code_count[code])\n",
    "print \"Prob ratio: %s\" % fps.code_prob_ratio(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code:20347 with count: {'spam_count': 1, 'ham_count': 0}\n",
      "Prob ratio: inf\n"
     ]
    }
   ],
   "source": [
    "code = es.word_encoding_dictionary.word_to_code(\"bacterial\")\n",
    "print \"Code:%s with count: %s\" % (code, fps.code_count[code])\n",
    "print \"Prob ratio: %s\" % fps.code_prob_ratio(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notice that the word *bacterial* and *compensating* have rare occurence in the data set. The probability we compute has a very noisy estimate for their true value. In other words, they are statistically insignificant for us to draw any reliable conclusion. It is not safe to make the assumption that every email with teh word *bacterial* is a spam email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Filter Low-reach Features\n",
    "Let's apply a limit to filter the words that have very low occurence in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Spam Features\n",
      "18629 | 2004 | {'spam_count': 121, 'ham_count': 1} | 296.208\n",
      "2252 | microsoft | {'spam_count': 98, 'ham_count': 11} | 21.8094545455\n",
      "5912 | investment | {'spam_count': 96, 'ham_count': 11} | 21.3643636364\n",
      "2993 | results | {'spam_count': 98, 'ham_count': 18} | 13.328\n",
      "4144 | v | {'spam_count': 134, 'ham_count': 26} | 12.6166153846\n",
      "1123 | million | {'spam_count': 97, 'ham_count': 20} | 11.8728\n",
      "4335 | stop | {'spam_count': 147, 'ham_count': 31} | 11.6082580645\n",
      "6730 | software | {'spam_count': 101, 'ham_count': 22} | 11.2385454545\n",
      "2189 | 80 | {'spam_count': 104, 'ham_count': 23} | 11.0692173913\n",
      "515 | dollars | {'spam_count': 113, 'ham_count': 26} | 10.6393846154\n",
      "1035 | remove | {'spam_count': 110, 'ham_count': 28} | 9.61714285714\n",
      "7768 | stock | {'spam_count': 84, 'ham_count': 22} | 9.34690909091\n",
      "6072 | removed | {'spam_count': 83, 'ham_count': 22} | 9.23563636364\n",
      "674 | money | {'spam_count': 187, 'ham_count': 50} | 9.15552\n",
      "1089 | world | {'spam_count': 124, 'ham_count': 34} | 8.928\n",
      "3351 | save | {'spam_count': 125, 'ham_count': 35} | 8.74285714286\n",
      "201 | http | {'spam_count': 475, 'ham_count': 135} | 8.61333333333\n",
      "3868 | quality | {'spam_count': 101, 'ham_count': 29} | 8.52579310345\n",
      "5253 | canada | {'spam_count': 79, 'ham_count': 23} | 8.40834782609\n",
      "4643 | low | {'spam_count': 106, 'ham_count': 31} | 8.37058064516\n",
      "\n",
      "\n",
      "Best Ham Features\n",
      "3 | meter | {'spam_count': 0, 'ham_count': 773} | 0.0\n",
      "27 | cotten | {'spam_count': 0, 'ham_count': 157} | 0.0\n",
      "38 | aimee | {'spam_count': 0, 'ham_count': 121} | 0.0\n",
      "42 | daren | {'spam_count': 0, 'ham_count': 1030} | 0.0\n",
      "48 | fyi | {'spam_count': 0, 'ham_count': 277} | 0.0\n",
      "91 | mmbtu | {'spam_count': 0, 'ham_count': 527} | 0.0\n",
      "105 | hpl | {'spam_count': 0, 'ham_count': 1098} | 0.0\n",
      "113 | hplno | {'spam_count': 0, 'ham_count': 107} | 0.0\n",
      "115 | xls | {'spam_count': 0, 'ham_count': 504} | 0.0\n",
      "230 | sitara | {'spam_count': 0, 'ham_count': 405} | 0.0\n",
      "235 | pops | {'spam_count': 0, 'ham_count': 102} | 0.0\n",
      "2284 | scheduling | {'spam_count': 0, 'ham_count': 129} | 0.0\n",
      "242 | volumes | {'spam_count': 0, 'ham_count': 437} | 0.0\n",
      "325 | pat | {'spam_count': 0, 'ham_count': 249} | 0.0\n",
      "326 | clynes | {'spam_count': 0, 'ham_count': 184} | 0.0\n",
      "328 | enron | {'spam_count': 0, 'ham_count': 1462} | 0.0\n",
      "379 | nominations | {'spam_count': 0, 'ham_count': 133} | 0.0\n",
      "411 | hplc | {'spam_count': 0, 'ham_count': 124} | 0.0\n",
      "420 | hsc | {'spam_count': 0, 'ham_count': 134} | 0.0\n",
      "453 | 6353 | {'spam_count': 0, 'ham_count': 112} | 0.0\n"
     ]
    }
   ],
   "source": [
    "from naive_bayes.feature_prob_selector import FeatureProbabilitySelector\n",
    "fps = FeatureProbabilitySet.from_email_set(es).filter_low_reach(limit=100)\n",
    "best_spam_features = FeatureProbabilitySelector.best_spam_features(fps)\n",
    "best_ham_features = FeatureProbabilitySelector.best_ham_features(fps)\n",
    "\n",
    "print \"Best Spam Features\"\n",
    "FeatureProbabilitySelector.print_feature_list(best_spam_features, es.word_encoding_dictionary)\n",
    "print \"\\n\"\n",
    "print \"Best Ham Features\"\n",
    "FeatureProbabilitySelector.print_feature_list(best_ham_features, es.word_encoding_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Using All Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconditional Independence\n",
    "Two variables are unconditionally independent, if knowing the result of one tells nothing of the other under any circumstance.\n",
    "\n",
    "For example, let `H` to be the event of flipping a head, and `S` to be the event of rolling a 6.\n",
    "\n",
    "$$\n",
    "P(S \\wedge  H) = P(S)P(H) \\\\\n",
    "P(H \\mid S) = P(H) \\\\\n",
    "P(S \\wedge H) = P(S)P(H \\mid S) = P(S)P(H)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Independence\n",
    "Let's denote the event of having a particular disease to be $D$, event for showing positive on test 1 for detecting the disease to be $T_{1}$, and event for showing positive on test 2 for detecting the same disease to be $T_{2}$. \n",
    "\n",
    "The following case is **NOT** unconditionally independent because it is conditional\n",
    "\n",
    "$$\n",
    "P(T_{1} \\mid T_{2}) \\neq P(T_{1})\n",
    "$$\n",
    "\n",
    "Given that we know test 2 is showing a positive result, it does influence the probability of having a positive on test 1, even though test 2 could have been a false positive. It is because a positive result from either tests can influence the probability of having the disease. The tworesults we have from $T_{1}$ and $T_{2}$ are connected by the variable $D$.\n",
    "\n",
    "$$\n",
    "P(T_{1} \\mid D) \\neq P(T_{1}) \\\\\n",
    "P(T_{2} \\mid D) \\neq P(T_{2})\n",
    "$$\n",
    "\n",
    "Even though the two events are not unconditionally independent, under some cases, aka conditions, they can be independent of each other. \n",
    "\n",
    "$$\n",
    "P(T_{1} \\mid T_{2} \\wedge D) = P(T_{1} \\mid D)\n",
    "$$\n",
    "\n",
    "This is saying that if the condition of having the disease is satisfied, then the probabilities of $T_{1}$ and $T_{2}$ are independent from each other. And equivalently speaking:\n",
    "\n",
    "$$\n",
    "P(T_{1} \\wedge T_{2} \\mid D) = P(T_{1} \\mid D) \\cdot P(T_{2} \\mid D)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Examples When Unconditional Independence is Violated\n",
    "Let's go back to the email examples. This is an example of conditional independence:\n",
    "\n",
    "$$\n",
    "P(LIMITED = 1 \\mid OFFER = 1) \\neq P(LIMIT = 1)\n",
    "$$\n",
    "\n",
    "The two random variables are not independent of each other in this particular condition because:\n",
    "\n",
    "* The presence of the word *offer* suggests that the email is spam.\n",
    "* If the email is spam, then it is more likely to contain the word *limited*.\n",
    "* Therefore, the presence of the word *offer* makes the presence of the word *limited* more likely.\n",
    "* In conclusion, the words *limited* and *offer* are **NOT** unconditionally independent. They are conditional independent in the sense that in some conditions they are dependent of each other and some conditions they are truly independent.\n",
    "\n",
    "$$\n",
    "P(LIMITED = 1 \\mid OFFER = 1) > P(LIMITED = 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However if we already knew the email is a spam email, then learning that we have the word *offer* doesn't add any new knowledge to our estimate of probability of seeing the word *limited*.\n",
    "\n",
    "$$\n",
    "P(LIMITED = 1 \\mid OFFER = 1 \\wedge SPAM = 1) = P(LIMITED = 1 \\mid SPAM = 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples When Conditional Independence is Violated\n",
    "The words *limited* and *offer* often appear together in spam email because they frequently appear as part of the compound phrase *a limited time offer*. In this sense, the probability of finding one word while other one is present is definitely not independent. \n",
    "\n",
    "$$\n",
    "P(LIMITED=1 \\mid SPAM=1 \\wedge OFFER=1) > P(LIMITED=1 \\mid SPAM=1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we naively assume independence\n",
    "\n",
    "$$\n",
    "P(LIMITED=1 \\wedge OFFER =1 \\mid SPAM=1) = P(LIMITED=1 \\mid SPAM=1) \\cdot P(OFFER=1 \\mid SPAM=1)\n",
    "$$\n",
    "\n",
    "It enables us to separate terms for ease of calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying The Naive Assumption\n",
    "For abbreviation, I will write $LIMITED = 1$ as $L$ and $LIMITED = 0$ as $L_{c}$. Same applies to other variables.\n",
    "\n",
    "We are trying to calculate the probability ratio of the following:\n",
    "\n",
    "$$\n",
    "\\frac{P(S \\mid L \\wedge O)}{P(S_{c} \\mid L \\wedge O)}\n",
    "$$\n",
    "\n",
    "Using Bayes' rule, we can rewrite them as:\n",
    "\n",
    "$$\n",
    "\\frac{P(S)}{P(S_{c})} \\cdot \\frac{P(L \\wedge O \\mid S)}{P(L \\wedge O \\mid S_{c})}\n",
    "$$\n",
    "\n",
    "Using the **naive** assumption, we can break the terms apart and simplify the expression\n",
    "\n",
    "$$\n",
    "P(L \\wedge O \\mid S) = P(L \\mid S) \\cdot P(O \\mid S) \\\\\n",
    "P(L \\wedge O \\mid S_{c}) = P(L \\mid S_{c}) \\cdot P(O \\mid S_{c})\n",
    "$$\n",
    "\n",
    "In conclusion, \n",
    "\n",
    "$$\n",
    "\\frac{P(S)}{P(S_{c})} \\cdot \\frac{P(L \\mid S)}{P(L \\mid S_{c})} \\cdot \\frac{P(O \\mid S)}{P(O \\mid S_{c})} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Generally Speaking\n",
    "\n",
    "$$\n",
    "\\frac{P(S \\mid W_{i} ... W_{N})}{P(S_{c} \\mid W_{i} ... W_{N})} = \\frac{P(S)}{P(S_{c})} \\cdot \\prod_{i}^{N} \\frac{P(W_{i} \\mid S)}{P(W_{i} \\mid S_{c})}\n",
    "$$\n",
    "\n",
    "If we wish to improve the performance of the classifier, we should also include that probability ratio of words that do not appear in the email. For example, in this Enron dataset, the word *enron* NOT appearing in the email could be a good indicator that the email is spam. \n",
    "\n",
    "If a word doesn't appear in the text/email, we just need to calculate *the probability of not having the word given an email is spam* and *the probability of not having the word given an email is ham*. \n",
    "\n",
    "$$\n",
    "AbsenceRatio = \\frac{P(W_{c} \\mid S)}{P(W_{c} \\mid S_{c})} = \\frac{1 - P(W \\mid S)}{1 - P(W \\mid S_{c})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true_positive_rate': 0.998, 'false_positive_rate': 0.09994553376906318}\n",
      "{'true_positive_rate': 0.998, 'false_positive_rate': 0.09068627450980392}\n",
      "{'true_positive_rate': 0.998, 'false_positive_rate': 0.08088235294117647}\n",
      "{'true_positive_rate': 0.9966666666666667, 'false_positive_rate': 0.07053376906318083}\n",
      "{'true_positive_rate': 0.9966666666666667, 'false_positive_rate': 0.06018518518518518}\n",
      "{'true_positive_rate': 0.9913333333333333, 'false_positive_rate': 0.04847494553376906}\n",
      "{'true_positive_rate': 0.9753333333333334, 'false_positive_rate': 0.03567538126361656}\n",
      "{'true_positive_rate': 0.9493333333333334, 'false_positive_rate': 0.02423747276688453}\n"
     ]
    }
   ],
   "source": [
    "from naive_bayes.naive_bayes_model import NaiveBayesModel\n",
    "from naive_bayes.naive_bayes_model import classification_accuracy\n",
    "\n",
    "model = NaiveBayesModel(fps)\n",
    "\n",
    "ham_scores = model.email_scores(es.ham_emails)\n",
    "spam_scores = model.email_scores(es.spam_emails)\n",
    "\n",
    "cutoff_prob_ratios = [0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "for cutoff in cutoff_prob_ratios:\n",
    "    result = classification_accuracy(cutoff, ham_scores, spam_scores)\n",
    "    print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training & Test Set\n",
    "Let's split the data and see how well the model performs on unseen data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 3328 ham emails and 1344 spam emails\n",
      "Test set has 344 ham emails and 156 spam emails\n",
      "{'true_positive_rate': 0.9901639344262295, 'false_positive_rate': 0.08803301237964237}\n",
      "{'true_positive_rate': 0.9868852459016394, 'false_positive_rate': 0.08390646492434663}\n",
      "{'true_positive_rate': 0.9868852459016394, 'false_positive_rate': 0.07702888583218707}\n",
      "{'true_positive_rate': 0.9836065573770492, 'false_positive_rate': 0.06740027510316368}\n",
      "{'true_positive_rate': 0.9770491803278688, 'false_positive_rate': 0.0577716643741403}\n",
      "{'true_positive_rate': 0.9672131147540983, 'false_positive_rate': 0.048143053645116916}\n",
      "{'true_positive_rate': 0.9377049180327869, 'false_positive_rate': 0.037138927097661624}\n",
      "{'true_positive_rate': 0.898360655737705, 'false_positive_rate': 0.017881705639614855}\n"
     ]
    }
   ],
   "source": [
    "training_set, test_set = es.split(0.80)\n",
    "print \"Training set has %s ham emails and %s spam emails\" % (len(training.ham_emails), len(training.spam_emails))\n",
    "print \"Test set has %s ham emails and %s spam emails\" % (len(test.ham_emails), len(test.spam_emails))\n",
    "\n",
    "fps = FeatureProbabilitySet.from_email_set(training_set).filter_low_reach(limit=100)\n",
    "model = NaiveBayesModel(fps)\n",
    "\n",
    "ham_scores = model.email_scores(test_set.ham_emails)\n",
    "spam_scores = model.email_scores(test_set.spam_emails)\n",
    "\n",
    "cutoff_prob_ratios = [0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "for cutoff in cutoff_prob_ratios:\n",
    "    result = classification_accuracy(cutoff, ham_scores, spam_scores)\n",
    "    print result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
