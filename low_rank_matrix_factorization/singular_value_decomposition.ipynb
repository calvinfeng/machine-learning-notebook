{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition\n",
    "\n",
    "Using our movie recommendation as an example, we are given a rating matrix $R$ and we wish to perform a singular value decomposition on such matrix, such that\n",
    "\n",
    "$$\n",
    "R = U \\Sigma M^{T}\n",
    "$$\n",
    "\n",
    "The sigma matrix is said to be our diagonal singular matrix, with singular values filling up its diagonal sorted in decreasing order. The top left corner singular value has the highest value and it descendes as we move toward the bottom right. The U matrix and M matrix represent the latent information for each of our users and movies. However, before we dive too deep into the details, let's do a refresher on singular value decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving SVD\n",
    "Using conventional definition, given a matrix A, we want to decompose it into three different matrices, $U$, $\\Sigma$ and $V$. We need to first construct a symmetric matrix of $A$ using $A^{T}A$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.  0.]\n",
      " [ 3. -5.]]\n",
      "[[ 25. -15.]\n",
      " [-15.  25.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simple example \n",
    "A = np.array([[4, 0], [3, -5]], dtype='float')\n",
    "print A\n",
    "print A.T.dot(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we find the eigenvalues and eigenvectors of this symmetric matrix of $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals,eig_vecs =  np.linalg.eig(A.T.dot(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the square root of its eigenvalues to construct a singular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.32455532 0.        ]\n",
      " [0.         3.16227766]]\n"
     ]
    }
   ],
   "source": [
    "# Singular values are the sqrt of eigenvalues of (A.T)(A)\n",
    "s1, s2 = np.sqrt(eig_vals)\n",
    "S = np.array([[s1, 0], [0, s2]])\n",
    "\n",
    "# Notice that singular values are sorted from the greatest to least\n",
    "print S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the eigenvectors as columns of our V matrix. In this case, numpy has already done it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70710678  0.70710678]\n",
      " [-0.70710678  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "V = eig_vecs\n",
    "print V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can solve for U using $U = AVS^{-1}$, note that $S^{-1}$ is the inverse of $S$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4472136   0.89442719]\n",
      " [ 0.89442719 -0.4472136 ]]\n"
     ]
    }
   ],
   "source": [
    "U = A.dot(V).dot(np.linalg.inv(S))\n",
    "print U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD is now complete, we can easily verify it by performing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True],\n",
       "       [ True,  True]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(A, U.dot(S).dot(V.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition in Recommendation\n",
    "\n",
    "There are several properties of SVD we should know about \n",
    "\n",
    "* It is always possible to decompose a real valued matrix into $U \\Sigma V^{T}$\n",
    "* $U$, $\\Sigma$, and $V$ are unique\n",
    "* $U$ and $V$ are column orthogonal i.e. $U^{T}U = I$ and $V^{T}V = I$\n",
    "* $\\Sigma$ entries are positive and sorted in descending order\n",
    "\n",
    "Going back to the movie example, imagine that we have 4 movies\n",
    "\n",
    "* Toy Story\n",
    "* Finding Nemo\n",
    "* Braveheart\n",
    "* Last Samurai\n",
    "\n",
    "And we have 4 users\n",
    "\n",
    "* Alice\n",
    "* Bob\n",
    "* Calvin\n",
    "* Debby\n",
    "\n",
    "We have the following rating matrix from the submitted ratings by each user. And notice that half of the users likes Pixar animated films a lot while the other half tends to have strong preference toward historical films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating = np.array([\n",
    "    [5, 5, 1, 2],\n",
    "    [1, 1, 5, 5],\n",
    "    [2, 1, 5, 5],\n",
    "    [5, 5, 1, 1]\n",
    "], dtype='float')\n",
    "\n",
    "# Now let's perform SVD decomposition on this dataset.\n",
    "eig_vals, eig_vecs =  np.linalg.eig(Rating.T.dot(Rating))\n",
    "s1, s2, s3, s4 = np.sqrt(eig_vals)\n",
    "\n",
    "# Let's say we only care about two features, i.e. whether it's animated film or historical film. We will drop the\n",
    "# other two less important singular values and eigenvectors\n",
    "S = np.array([[s1, 0], [0, s2]])\n",
    "M = np.delete(eig_vecs, [2, 3],axis=1)\n",
    "U = Rating.dot(M).dot(np.linalg.inv(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.52079729,  0.        ],\n",
       "       [ 0.        ,  7.53112887]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52034736, -0.46796508],\n",
       "       [-0.47878871, -0.53010252],\n",
       "       [-0.47878871,  0.53010252],\n",
       "       [-0.52034736,  0.46796508]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52034736, -0.46796508],\n",
       "       [-0.47878871,  0.53010252],\n",
       "       [-0.52034736,  0.46796508],\n",
       "       [-0.47878871, -0.53010252]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the user matrix, we can clearly see that user 1 and user 4 are similar to each other in interest and user 2 and 3 are also similar to each other. This is telling us that Alice and Debby have similar taste in movies and Calvin and Bob share interest in historical drama.\n",
    "\n",
    "## Low Rank Matrix Factorization\n",
    "What we did up there is effectively a low rank apprixomation. The original singular matrix had a rank 4 but we learned that most of the singular values are not really important. We dropped the extra 2 ranks and we can still produce a matrix that similar to the original one. \n",
    "\n",
    "For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.03940005 4.98763    1.25114372 1.7408964 ]\n",
      " [1.25114372 0.75393781 4.98656303 4.98763   ]\n",
      " [1.7408964  1.25114372 4.98763    5.03940005]\n",
      " [4.98763    4.98656303 0.75393781 1.25114372]]\n"
     ]
    }
   ],
   "source": [
    "approximated_rating = U.dot(S).dot(M.T)\n",
    "print approximated_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 5., 1., 2.],\n",
       "       [1., 1., 5., 5.],\n",
       "       [2., 1., 5., 5.],\n",
       "       [5., 5., 1., 1.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Roud it up\n",
    "np.round(approximated_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look! It looks just like the original!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
